{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd48119e",
   "metadata": {},
   "source": [
    "## data set \n",
    "[Predict Future Sales](https://www.kaggle.com/c/competitive-data-science-predict-future-sales)\n",
    "\n",
    "* File descriptions\n",
    "    * sales_train.csv - 훈련 세트. 2013년 1월부터 2015년 10월까지의 일일 과거 데이터입니다.\n",
    "    * items.csv - 항목/제품에 대한 추가 정보입니다.\n",
    "    * test.csv -  테스트 세트. 2015년 11월 이러한 상점 및 제품의 매출을 예측해야 합니다.\n",
    "    * sample_submission.csv - 올바른 형식의 샘플 제출 파일입니다.\n",
    "\n",
    "* data fields\n",
    "    * ID  - 테스트 세트 내 (Shop, Item) 튜플을 나타내는 ID\n",
    "    * shop_id - 상점의 고유 식별자\n",
    "    * item_id - 제품의 고유 식별자\n",
    "    * item_category_id - 항목 카테고리의 고유 식별자\n",
    "    * item_cnt_day - 판매된 제품 수. 이 측정값의 월별 금액을 예측하고 있습니다.\n",
    "    * item_price - 항목의 현재 가격\n",
    "    * date  - dd/mm/yyyy 형식의 날짜\n",
    "    * date_block_num - 편의를 위해 사용되는 연속 월 숫자입니다. 2013년 1월은 0, 2013년 2월은 1,..., 2015년 10월은 33\n",
    "\n",
    "item_categories.csv 과 shop.csv 는 이름 - 번호 정보만 있어서 사용하지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adebabe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_seed = 1234\n",
    "scoring = 'neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc21417f",
   "metadata": {},
   "source": [
    "각 데이터 파일을 불러와 출력한 결과는 다음과 같다. cnt 가 0보다 작은 경우도 있는데  \n",
    "환불된 상품의 경우 마이너스 값이 들어가는 것으로 추정된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822d4654",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
      "0  02.01.2013               0       59    22154      999.00           1.0\n",
      "1  03.01.2013               0       25     2552      899.00           1.0\n",
      "2  05.01.2013               0       25     2552      899.00          -1.0\n",
      "3  06.01.2013               0       25     2554     1709.05           1.0\n",
      "4  15.01.2013               0       25     2555     1099.00           1.0\n",
      "sales_train data :  2935849 \n",
      "\n",
      "   item_id  item_category_id\n",
      "0        0                40\n",
      "1        1                76\n",
      "2        2                40\n",
      "3        3                40\n",
      "4        4                40\n",
      "items data num :  22170\n",
      "category num :  84 \n",
      "\n",
      "   ID  shop_id  item_id\n",
      "0   0        5     5037\n",
      "1   1        5     5320\n",
      "2   2        5     5233\n",
      "3   3        5     5232\n",
      "4   4        5     5268\n",
      "test data num :  214200 \n",
      "\n",
      "         date  date_block_num  shop_id  item_id  item_price  item_cnt_day  \\\n",
      "0  02.01.2013               0       59    22154      999.00           1.0   \n",
      "1  03.01.2013               0       25     2552      899.00           1.0   \n",
      "2  05.01.2013               0       25     2552      899.00          -1.0   \n",
      "3  06.01.2013               0       25     2554     1709.05           1.0   \n",
      "4  15.01.2013               0       25     2555     1099.00           1.0   \n",
      "\n",
      "   item_category_id  \n",
      "0                37  \n",
      "1                58  \n",
      "2                58  \n",
      "3                58  \n",
      "4                56  \n",
      "sales - items merge data :  2935849 \n",
      "\n",
      "기타 정보\n",
      "shop data num :  60\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sales_train = pd.read_csv(\"./data/sales_train.csv\")\n",
    "print(sales_train.head())\n",
    "print(\"sales_train data : \", len(sales_train), \"\\n\")\n",
    "\n",
    "items = pd.read_csv(\"./data/items.csv\")\n",
    "items = items.drop(\"item_name\", axis = 1)\n",
    "print(items.head())\n",
    "print(\"items data num : \", len(items))\n",
    "print(\"category num : \", len(items.groupby(\"item_category_id\")), \"\\n\")\n",
    "\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "print(test.head())\n",
    "print(\"test data num : \", len(test), \"\\n\")\n",
    "\n",
    "sales_train2 = pd.merge(sales_train, items, on = \"item_id\", how = \"left\") \n",
    "print(sales_train2.head())\n",
    "print(\"sales - items merge data : \", len(sales_train2), \"\\n\")\n",
    "\n",
    "shop = pd.read_csv(\"./data/shops.csv\")\n",
    "print(\"기타 정보\")\n",
    "print(\"shop data num : \", len(shop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee32d7f6",
   "metadata": {},
   "source": [
    "아래는 다른 자료를 참고하기 전에 먼저 분석해본 내용.  \n",
    "한번 학습을 시켜 보면서 감을 잡은 후, 해당 프로젝트와 관련된 다른 사람들의 코드나 자료를 참고하여 개선할 것임.  \n",
    "<br>\n",
    "## 문제 분석\n",
    "우선, test 데이터와 submission 형식을 보았을 때  \n",
    "예측 모델을 만들 경우 <data_block_num> <shop_id> <item_id> 가 입력 데이터의 기준이 되고, 출력데이터는 월별 매출이 되어야 하는 것으로 보인다.  \n",
    "<br>\n",
    "이제 위의 입력의 기준이 되는 정보들에 대해 설명하는 데이터를 만들고 학습에 사용할 것이다.  \n",
    "(**shop_id, item_id 와 같은 정보는 그상태 그대로는 아무런 의미가 없으므로, 이를 수치적으로 의미 있는 정보로 변환해야 한다.**)  \n",
    "여기서 어떤 정보가 도움이 되는 가에 대해서 다음과 같이 정리해 보았다.  \n",
    "<br>\n",
    "가장 먼저 생각해보아야 할 것은 \"**이전 date 들에서 해당 item 이 해당 shop 에 대해서 얼마나 많이 팔렸는가 ?**\" 이다.    \n",
    "만약 데이터가 아주 충분해서 모든 shop 이 모든 item 에 대하여 매출 데이터를 가지고 있다면, 그 정보만 가지고 평균을 내거나 회귀함수를 만들어도 어느 정도는 맞겠지만  \n",
    "**아래에서 보다싶이 shop 마다 모든 아이템에 대한 판매기록이 있는 것이 아니므로**, shop 이나 item category 의 매출 등 다른 정보를 활용해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8482e18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_id\n",
      "0     3600\n",
      "1     2523\n",
      "2     4849\n",
      "3     5261\n",
      "4     7309\n",
      "5     7084\n",
      "6    11856\n",
      "7     8246\n",
      "8     1909\n",
      "9     1404\n",
      "Name: item_id, dtype: int64\n",
      "\n",
      "mean :  7068.733333333334\n"
     ]
    }
   ],
   "source": [
    "# shop 마다 판매한 아이템의 종류 중복 없이 출력\n",
    "\n",
    "sales_train_g_sh =  sales_train.groupby('shop_id')['item_id'].nunique()\n",
    "print(sales_train_g_sh[:10])\n",
    "\n",
    "rr = sales_train_g_sh.reset_index()\n",
    "print(\"\\nmean : \", rr['item_id'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1332051",
   "metadata": {},
   "source": [
    "따라서 shop_id, item_id 에 따른 달별 매출 예측에 영향을 끼칠 수 있는 정보를 다음과 같이 정리하였다.\n",
    "\n",
    "**1. 해당 shop 에서 해당 item 의 매출 정보**\n",
    "**2. 모든 shop 에서 해당 item 의 매출 정보**\n",
    "**3. 해당 shop 의 매출 정보**\n",
    "**84. 해당 item 의 category 매출 정보**  \n",
    "<br><br>\n",
    "\n",
    "item_price 등의 정보도 있지만 일단은 위의 네가지만 고려함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1176171b",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "여러가지 시도를 해보기 전에 당장 떠오르는 가장 단순한 모델로 학습시켜보면 어느정도 성능이 나오는지 확인해 보기로 하였다.  \n",
    "<br>\n",
    "**특정 shop 의 item 에 대하여**,  \n",
    "<해당 shop에서 아이템의 이전 달 매출> <모든 shop에서 아이템의 이전 달 매출 평균> <해당 shop 의 이전 달 매출 평균> <해당 category 의 이전 달 매출> 이 입력되면  \n",
    "**해당 month의 매출을 출력** 하는 회귀 모델을 학습시켜 볼 것이다.  \n",
    "<br>\n",
    "**<poly regerssion 에서 시도할 수 있는 다른 방법?>**  \n",
    "이전 달의 매출만 가져오는 대신 그 이전의 매출까지 포괄할 수 있는 값을 사용하거나(ex.지수 가중 평균)  \n",
    "item 의 이전 매출을 넣는 대신 달 정보(data_block_num) 를 입력값으로 들어가게 해서 달 - 매출 관계가 회귀학습되도록 하는 등  \n",
    "다양한 방법을 사용할 수 있을 것 같지만 일단은 위와 같이 simple 한 형태의 데이터로 테스트 해 볼 것임.\n",
    "\n",
    "\n",
    "<br>\n",
    "아래는 각 데이터를 뽑는 과정이다.  \n",
    "<br><br>\n",
    "\n",
    "### 반응 변수 (item_cnt)\n",
    "기존의 sales_trian 은 item 매출이 발생할때마다 기록된 데이터이므로, 이를 data_block_num / shop_id / item_id 로 group 지어 item_cnt 의 sum을 출력함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7a7aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date_block_num  shop_id  item_id  item_cnt_day\n",
      "0               0       59    22154           1.0\n",
      "1               0       25     2552           1.0\n",
      "2               0       25     2552          -1.0\n",
      "3               0       25     2554           1.0\n",
      "4               0       25     2555           1.0\n",
      "selected data :  2935849 \n",
      "\n",
      "                                item_cnt_day\n",
      "date_block_num shop_id item_id              \n",
      "0              0       32                6.0\n",
      "                       33                3.0\n",
      "                       35                1.0\n",
      "                       43                1.0\n",
      "                       51                2.0\n",
      "group by data_block_num / shop_id / item_id :  1609124 \n",
      "\n",
      "(sales_train -> montly_sales) data num rate :  54.81 %\n"
     ]
    }
   ],
   "source": [
    "sales = sales_train.drop([\"date\", \"item_price\"], axis = 1)\n",
    "print(sales.head())\n",
    "print(\"selected data : \", len(sales), \"\\n\")\n",
    "\n",
    "montly_sales = sales.groupby([\"date_block_num\", \"shop_id\", \"item_id\"]).sum()\n",
    "print(montly_sales.head())\n",
    "print(\"group by data_block_num / shop_id / item_id : \", len(montly_sales), \"\\n\")\n",
    "\n",
    "print(\"(sales_train -> montly_sales) data num rate : \", round(len(montly_sales)/len(sales_train)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f46a807",
   "metadata": {},
   "source": [
    "groupby 로 집계한 내용을 다시 dataframe 형식으로 변환.  \n",
    "item_cnt_day 를 item_cnt_month 로 변경."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25390b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date_block_num  shop_id  item_id  item_cnt_month\n",
      "0                     0        0       32             6.0\n",
      "1                     0        0       33             3.0\n",
      "2                     0        0       35             1.0\n",
      "3                     0        0       43             1.0\n",
      "4                     0        0       51             2.0\n",
      "...                 ...      ...      ...             ...\n",
      "1609119              33       59    22087             6.0\n",
      "1609120              33       59    22088             2.0\n",
      "1609121              33       59    22091             1.0\n",
      "1609122              33       59    22100             1.0\n",
      "1609123              33       59    22102             1.0\n",
      "\n",
      "[1609124 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "montly_sales = montly_sales.reset_index()\n",
    "montly_sales.rename(columns = {\"item_cnt_day\": \"item_cnt_month\"}, inplace = True)\n",
    "print(montly_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972760c",
   "metadata": {},
   "source": [
    "이전 달 매출을 사용하여 예측한다는 설정이므로 첫번 째 달(date_block_num = 0) 인 데이터는 제외 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c86c0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date_block_num  shop_id  item_id  item_cnt_month\n",
      "63224                 1        0       30            31.0\n",
      "63225                 1        0       31            11.0\n",
      "63226                 1        0       32            10.0\n",
      "63227                 1        0       33             3.0\n",
      "63228                 1        0       35            14.0\n",
      "...                 ...      ...      ...             ...\n",
      "1609119              33       59    22087             6.0\n",
      "1609120              33       59    22088             2.0\n",
      "1609121              33       59    22091             1.0\n",
      "1609122              33       59    22100             1.0\n",
      "1609123              33       59    22102             1.0\n",
      "\n",
      "[1545900 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "montly_sales_except0 = montly_sales[montly_sales.date_block_num != 0]\n",
    "print(montly_sales_except0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5198c8e",
   "metadata": {},
   "source": [
    "### 설명 변수 1 (해당 shop에서 아이템의 이전 달 매출)\n",
    "montly_sales 데이터 그대로 date_block_num 에 1을 더해서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ceee68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date_block_num  shop_id  item_id  shop_item_cnt\n",
      "0                     1        0       32            6.0\n",
      "1                     1        0       33            3.0\n",
      "2                     1        0       35            1.0\n",
      "3                     1        0       43            1.0\n",
      "4                     1        0       51            2.0\n",
      "...                 ...      ...      ...            ...\n",
      "1609119              34       59    22087            6.0\n",
      "1609120              34       59    22088            2.0\n",
      "1609121              34       59    22091            1.0\n",
      "1609122              34       59    22100            1.0\n",
      "1609123              34       59    22102            1.0\n",
      "\n",
      "[1609124 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "shop_item_cnt = montly_sales.copy()\n",
    "\n",
    "date_block_num = shop_item_cnt[\"date_block_num\"]\n",
    "add_1 = pd.Series([1]*len(montly_sales))\n",
    "\n",
    "date_block_num = date_block_num.add(add_1, fill_value=0)\n",
    "\n",
    "shop_item_cnt['date_block_num'] = date_block_num\n",
    "\n",
    "shop_item_cnt.rename(columns = {\"item_cnt_month\": \"shop_item_cnt\"}, inplace = True)\n",
    "print(shop_item_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578296f8",
   "metadata": {},
   "source": [
    "### 설명 변수 2 (모든 shop에서 아이템의 이전 달 매출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58702b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date_block_num  item_id  item_cnt\n",
      "0                    1       19       1.0\n",
      "1                    1       27       7.0\n",
      "2                    1       28       8.0\n",
      "3                    1       29       4.0\n",
      "4                    1       32     299.0\n",
      "...                ...      ...       ...\n",
      "233907              34    22162      10.0\n",
      "233908              34    22163      26.0\n",
      "233909              34    22164      15.0\n",
      "233910              34    22166      11.0\n",
      "233911              34    22167      37.0\n",
      "\n",
      "[233912 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "item_cnt = shop_item_cnt.copy()\n",
    "item_cnt = item_cnt.drop(\"shop_id\", axis = 1)\n",
    "\n",
    "item_cnt = item_cnt.groupby([\"date_block_num\", \"item_id\"]).sum()\n",
    "item_cnt = item_cnt.reset_index()\n",
    "\n",
    "item_cnt.rename(columns = {\"shop_item_cnt\": \"item_cnt\"}, inplace = True)\n",
    "print(item_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf40e9",
   "metadata": {},
   "source": [
    "### 설명 변수 3 (해당 shop 의 이전 달 매출)\n",
    "shop cnt 는 최대 1980 개(33 * 60) 나올거라고 생각했는데 실제로는 1585 개가 출력됨.  \n",
    "rows 를 전부 출력해보았고, 모든 shop 이 33개의 month 에서 아이템 판매 기록을 가지진 않은 것을 확인하였음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c30854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date_block_num  shop_id  shop_cnt\n",
      "0                  1        0    5578.0\n",
      "1                  1        1    2947.0\n",
      "2                  1        2    1146.0\n",
      "3                  1        3     767.0\n",
      "4                  1        4    2114.0\n",
      "...              ...      ...       ...\n",
      "1581              34       55    1972.0\n",
      "1582              34       56    1263.0\n",
      "1583              34       57    2316.0\n",
      "1584              34       58    1446.0\n",
      "1585              34       59     790.0\n",
      "\n",
      "[1586 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "shop_cnt = shop_item_cnt.copy()\n",
    "shop_cnt = shop_cnt.drop(\"item_id\", axis = 1)\n",
    "\n",
    "shop_cnt = shop_cnt.groupby([\"date_block_num\", \"shop_id\"]).sum()\n",
    "shop_cnt = shop_cnt.reset_index()\n",
    "\n",
    "shop_cnt.rename(columns = {\"shop_item_cnt\": \"shop_cnt\"}, inplace = True)\n",
    "print(shop_cnt)\n",
    "\n",
    "#with pd.option_context(\"display.max_rows\", None):\n",
    "#    print(shop_cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c99c7d",
   "metadata": {},
   "source": [
    "### 설명 변수 4 (해당 category 의 이전 달 매출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2758da8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date_block_num  item_category_id  category_cnt\n",
      "0                  0                 0           1.0\n",
      "1                  0                 1           1.0\n",
      "2                  0                 2        1390.0\n",
      "3                  0                 3         440.0\n",
      "4                  0                 4         251.0\n",
      "...              ...               ...           ...\n",
      "2072              33                76         184.0\n",
      "2073              33                77          64.0\n",
      "2074              33                78          64.0\n",
      "2075              33                79         521.0\n",
      "2076              33                83         348.0\n",
      "\n",
      "[2077 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "category_cnt = sales_train2.copy()\n",
    "category_cnt = category_cnt.drop([\"shop_id\", \"item_id\", \"item_price\"], axis = 1)\n",
    "\n",
    "category_cnt = category_cnt.groupby([\"date_block_num\", \"item_category_id\"]).sum()\n",
    "category_cnt = category_cnt.reset_index()\n",
    "\n",
    "category_cnt.rename(columns = {\"item_cnt_day\": \"category_cnt\"}, inplace = True)\n",
    "print(category_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa52742",
   "metadata": {},
   "source": [
    "### train data set\n",
    "montly_sales_except 에 설명 변수 4가지의 dataframe 들을 차례차례 merge 한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4642db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = montly_sales_except0.loc[:, montly_sales.columns != \"item_cnt_month\"]\n",
    "train_y = montly_sales_except0[\"item_cnt_month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf7621dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date_block_num  shop_id  item_id  shop_item_cnt  item_cnt  shop_cnt  \\\n",
      "0                     1        0       30            0.0       0.0    5578.0   \n",
      "1                     1        0       31            0.0       0.0    5578.0   \n",
      "2                     1        0       32            6.0     299.0    5578.0   \n",
      "3                     1        0       33            3.0      61.0    5578.0   \n",
      "4                     1        0       35            1.0      78.0    5578.0   \n",
      "...                 ...      ...      ...            ...       ...       ...   \n",
      "1545895              33       59    22087            3.0      60.0     914.0   \n",
      "1545896              33       59    22088            1.0     130.0     914.0   \n",
      "1545897              33       59    22091            3.0      43.0     914.0   \n",
      "1545898              33       59    22100            1.0      94.0     914.0   \n",
      "1545899              33       59    22102            0.0     144.0     914.0   \n",
      "\n",
      "         item_category_id  category_cnt  \n",
      "0                      40       31649.0  \n",
      "1                      37        6307.0  \n",
      "2                      40       31649.0  \n",
      "3                      37        6307.0  \n",
      "4                      40       31649.0  \n",
      "...                   ...           ...  \n",
      "1545895                83         348.0  \n",
      "1545896                83         348.0  \n",
      "1545897                83         348.0  \n",
      "1545898                42         934.0  \n",
      "1545899                42         934.0  \n",
      "\n",
      "[1545900 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "train_X = pd.merge(train_X, shop_item_cnt, on = [\"date_block_num\", \"shop_id\", \"item_id\"], how = \"left\") \n",
    "train_X[\"shop_item_cnt\"] = train_X[\"shop_item_cnt\"].fillna(0)\n",
    "\n",
    "train_X = pd.merge(train_X, item_cnt, on = [\"date_block_num\", \"item_id\"], how = \"left\")\n",
    "train_X[\"item_cnt\"] = train_X[\"item_cnt\"].fillna(0)\n",
    "\n",
    "train_X = pd.merge(train_X, shop_cnt, on = [\"date_block_num\", \"shop_id\"], how = \"left\")\n",
    "train_X[\"shop_cnt\"] = train_X[\"shop_cnt\"].fillna(0)\n",
    "\n",
    "# categoty_cnt 는 merge 하기 전 train_X 에 category 정보 자체가 먼저 들어가야 한다. \n",
    "train_X = pd.merge(train_X, items, on = \"item_id\", how = \"left\") \n",
    "train_X = pd.merge(train_X, category_cnt, on = [\"date_block_num\", \"item_category_id\"], how = \"left\")\n",
    "train_X[\"category_cnt\"] = train_X[\"category_cnt\"].fillna(0)\n",
    "\n",
    "print(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e502bc",
   "metadata": {},
   "source": [
    "train_X 에서 id 값들을 제거하고, 설명변수 값들만을 남긴다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b444b5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X : \n",
      "         shop_item_cnt  item_cnt  shop_cnt  category_cnt\n",
      "0                  0.0       0.0    5578.0       31649.0\n",
      "1                  0.0       0.0    5578.0        6307.0\n",
      "2                  6.0     299.0    5578.0       31649.0\n",
      "3                  3.0      61.0    5578.0        6307.0\n",
      "4                  1.0      78.0    5578.0       31649.0\n",
      "...                ...       ...       ...           ...\n",
      "1545895            3.0      60.0     914.0         348.0\n",
      "1545896            1.0     130.0     914.0         348.0\n",
      "1545897            3.0      43.0     914.0         348.0\n",
      "1545898            1.0      94.0     914.0         934.0\n",
      "1545899            0.0     144.0     914.0         934.0\n",
      "\n",
      "[1545900 rows x 4 columns]\n",
      "\n",
      "train_y : \n",
      "0          31.0\n",
      "1          11.0\n",
      "2          10.0\n",
      "3           3.0\n",
      "4          14.0\n",
      "           ... \n",
      "1545895     6.0\n",
      "1545896     2.0\n",
      "1545897     1.0\n",
      "1545898     1.0\n",
      "1545899     1.0\n",
      "Name: item_cnt_month, Length: 1545900, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_X = train_X.drop([\"date_block_num\", \"shop_id\", \"item_id\", \"item_category_id\"], axis = 1)\n",
    "train_y.index = list(range(0, 1545900))\n",
    "\n",
    "print(\"train_X : \")\n",
    "print(train_X)\n",
    "print(\"\\ntrain_y : \")\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c994c8a",
   "metadata": {},
   "source": [
    "numpy 자료형으로 변환하고 **normarlizing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0159d7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X numpy [:5] : \n",
      "[[-0.18587112 -0.22841774  0.85575128  2.69399191]\n",
      " [-0.18587112 -0.22841774  0.85575128 -0.33233613]\n",
      " [ 0.55067652  1.03142819  0.85575128  2.69399191]\n",
      " [ 0.1824027   0.02860768  0.85575128 -0.33233613]\n",
      " [-0.06311318  0.10023772  0.85575128  2.69399191]]\n",
      "(1545900, 4)\n",
      "\n",
      "train_y numpy [:5] : \n",
      "[31. 11. 10.  3. 14.]\n",
      "(1545900,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "train_X_np = train_X.to_numpy()\n",
    "train_y_np = train_y.to_numpy()\n",
    "\n",
    "std_scaler = preprocessing.StandardScaler().fit(train_X)\n",
    "train_X_np = std_scaler.transform(train_X)\n",
    "\n",
    "print(\"train_X numpy [:5] : \")\n",
    "print(train_X_np[:5])\n",
    "print(train_X_np.shape)\n",
    "\n",
    "print(\"\\ntrain_y numpy [:5] : \")\n",
    "print(train_y_np[:5])\n",
    "print(train_y_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b8c38",
   "metadata": {},
   "source": [
    "3차항 회귀를 하기 위해 PolynomialFeatures 사용. \n",
    "(sklearn 에서는 고차항 회귀가 모델이 아니라 데이터를 transform 함으로서 구현된다. 모델은 그대로 LinearRegression 사용.)  \n",
    "원래 한꺼번에 변환하려고 했으나 메모리 부족 오류(**Unable to allocate 441**) 가 발생해서 10개 묶음으로 나눠서 처리함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efec130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly = PolynomialFeatures(degree = 3, include_bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac159dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori data shape :  (1545900, 4)\n",
      "poly data shape :  (1545900, 34)\n",
      "\n",
      " poly data sample\n",
      "[-1.85871117e-01 -2.28417738e-01  8.55751281e-01  2.69399191e+00\n",
      "  3.45480721e-02  4.24562600e-02 -1.59059446e-01 -5.00735285e-01\n",
      "  5.21746628e-02 -1.95468771e-01 -6.15355536e-01  7.32310255e-01\n",
      "  2.30538702e+00  7.25759239e+00 -6.42148875e-03 -7.89139247e-03\n",
      "  2.95645570e-02  9.30722266e-02 -9.69776285e-03  3.63319989e-02\n",
      "  1.14376821e-01 -1.36115325e-01 -4.28504861e-01 -1.34897680e+00\n",
      " -1.19176184e-02  4.46485345e-02  1.40558119e-01 -1.67272652e-01\n",
      " -5.26591288e-01 -1.65776283e+00  6.26675439e-01  1.97283790e+00\n",
      "  6.21069398e+00  1.95518951e+01]\n"
     ]
    }
   ],
   "source": [
    "def make_poly_data(train_X_np, poly):\n",
    "\n",
    "    temp_list = []\n",
    "\n",
    "    split_num = 10\n",
    "    split_term = len(train_X_np)//split_num\n",
    "\n",
    "    for i in range(split_num):\n",
    "        temp_list.append(poly.fit_transform(train_X_np[i*split_term:(i+1)*split_term]))\n",
    "\n",
    "\n",
    "    if len(train_X_np)%split_num != 0:\n",
    "        temp_list.append(poly.fit_transform(train_X_np[split_num*split_term:]))\n",
    "    train_X_np_poly = np.concatenate(temp_list, axis = 0)\n",
    "\n",
    "    print(\"ori data shape : \", train_X_np.shape)\n",
    "    print(\"poly data shape : \", train_X_np_poly.shape)\n",
    "    print(\"\\n poly data sample\")\n",
    "    print(train_X_np_poly[0])\n",
    "    \n",
    "    return train_X_np_poly\n",
    "\n",
    "train_X_np_poly = make_poly_data(train_X_np, poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f546c",
   "metadata": {},
   "source": [
    "위에서 poly 가 적용된 34개의 feature 는  \n",
    "원래의 데이터 feature + 원래의 데이터에 차수가 적용된 값(다른 feature 와 iteraction 한 값까지 포함)  \n",
    "으로 구성된다.  \n",
    "<br>\n",
    "linearRegression 자체에도 편향의 역할을 하는 intercept_ 가 포함되어 있기 때문에 입력데이터에는 편향값을 포함시킬 필요가 없다고 생각하여 bias 는 추가하지 않았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adc02a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_regression_train(train_X, train_y, model):\n",
    "    kfold = model_selection.KFold(n_splits = 10, random_state = kfold_seed, shuffle = True)\n",
    "\n",
    "    cv_results_1 = model_selection.cross_val_score(model, train_X, train_y, cv = kfold, scoring = scoring, n_jobs = -1)\n",
    "    msg = \"%s: %f (%f)\" % (\"polynomial regression MSE\", cv_results_1.mean(), cv_results_1.std())\n",
    "    print(msg)\n",
    "\n",
    "    cv_results_2 = model_selection.cross_val_score(model, train_X, train_y, cv = kfold, scoring = \"r2\", n_jobs = -1)\n",
    "    msg = \"%s: %f (%f)\" % (\"polynomial regression r2\", cv_results_2.mean(), cv_results_2.std())\n",
    "    print(msg)\n",
    "    \n",
    "    return cv_results_1.mean(), cv_results_2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd923339",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "poly_regression_train(train_X_np_poly, train_y_np, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7a5d7",
   "metadata": {},
   "source": [
    "원래는 feature 를 전부 사용하려고 했으나, 34개의 feature 에 데이터가 백만개가 넘다보니 학습이 너무 오래걸렸다.  \n",
    "따라서 4 개의 feature 를 사용한 linear regression  \n",
    "4개의 feature 를 사용한 2차항 poly regression   \n",
    "3개의 feature 를 사용한 3차항 poly regression 을 각각 시도하였다.  \n",
    "<br>\n",
    "\n",
    "### 4개의 feature 를 사용한 linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05c49ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polynomial regression MSE: -44.048909 (11.096444)\n",
      "polynomial regression r2: 0.428368 (0.098420)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-44.04890873318833, 0.4283675136286716)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "poly_regression_train(train_X_np, train_y_np, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab436ca",
   "metadata": {},
   "source": [
    "### 4개의 feature 를 사용한 2차항 poly regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba0d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X numpy [:5] : \n",
      "[[-0.18587112 -0.22841774  0.85575128]\n",
      " [-0.18587112 -0.22841774  0.85575128]\n",
      " [ 0.55067652  1.03142819  0.85575128]\n",
      " [ 0.1824027   0.02860768  0.85575128]\n",
      " [-0.06311318  0.10023772  0.85575128]]\n",
      "(1545900, 3)\n",
      "\n",
      "train_y numpy [:5] : \n",
      "[31. 11. 10.  3. 14.]\n",
      "(1545900,) \n",
      "\n",
      "\n",
      "ori data shape :  (1545900, 3)\n",
      "poly data shape :  (1545900, 9)\n",
      "\n",
      " poly data sample\n",
      "[-0.18587112 -0.22841774  0.85575128  0.03454807  0.04245626 -0.15905945\n",
      "  0.05217466 -0.19546877  0.73231025]\n"
     ]
    }
   ],
   "source": [
    "# data merge\n",
    "train_X = montly_sales_except0.loc[:, montly_sales.columns != \"item_cnt_month\"]\n",
    "train_y = montly_sales_except0[\"item_cnt_month\"]\n",
    "\n",
    "train_X = pd.merge(train_X, shop_item_cnt, on = [\"date_block_num\", \"shop_id\", \"item_id\"], how = \"left\") \n",
    "train_X[\"shop_item_cnt\"] = train_X[\"shop_item_cnt\"].fillna(0)\n",
    "\n",
    "train_X = pd.merge(train_X, item_cnt, on = [\"date_block_num\", \"item_id\"], how = \"left\")\n",
    "train_X[\"item_cnt\"] = train_X[\"item_cnt\"].fillna(0)\n",
    "\n",
    "train_X = pd.merge(train_X, shop_cnt, on = [\"date_block_num\", \"shop_id\"], how = \"left\")\n",
    "train_X[\"shop_cnt\"] = train_X[\"shop_cnt\"].fillna(0)\n",
    "\n",
    "# 설명변수 제외하고 drop\n",
    "train_X = train_X.drop([\"date_block_num\", \"shop_id\", \"item_id\"], axis = 1)\n",
    "train_y.index = list(range(0, 1545900))\n",
    "\n",
    "# numpy 자료형으로 변환하고 standardization\n",
    "train_X_np = train_X.to_numpy()\n",
    "train_y_np = train_y.to_numpy()\n",
    "\n",
    "std_scaler = preprocessing.StandardScaler().fit(train_X)\n",
    "train_X_np = std_scaler.transform(train_X)\n",
    "\n",
    "print(\"train_X numpy [:5] : \")\n",
    "print(train_X_np[:5])\n",
    "print(train_X_np.shape)\n",
    "\n",
    "print(\"\\ntrain_y numpy [:5] : \")\n",
    "print(train_y_np[:5])\n",
    "print(train_y_np.shape, \"\\n\\n\")\n",
    "\n",
    "# polynomial data 로 변환\n",
    "poly = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "train_X_np_poly = make_poly_data(train_X_np, poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1b7bb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polynomial regression MSE: -43.099399 (11.667345)\n",
      "polynomial regression r2: 0.442412 (0.101046)\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "poly_regression_train(train_X_np_poly, train_y_np, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff99201",
   "metadata": {},
   "source": [
    "### 3개의 feature 를 사용한 3차항 poly regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d6a1141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X numpy [:5] : \n",
      "[[-0.18587112 -0.22841774  0.85575128]\n",
      " [-0.18587112 -0.22841774  0.85575128]\n",
      " [ 0.55067652  1.03142819  0.85575128]\n",
      " [ 0.1824027   0.02860768  0.85575128]\n",
      " [-0.06311318  0.10023772  0.85575128]]\n",
      "(1545900, 3)\n",
      "\n",
      "train_y numpy [:5] : \n",
      "[31. 11. 10.  3. 14.]\n",
      "(1545900,) \n",
      "\n",
      "\n",
      "ori data shape :  (1545900, 3)\n",
      "poly data shape :  (1545900, 19)\n",
      "\n",
      " poly data sample\n",
      "[-0.18587112 -0.22841774  0.85575128  0.03454807  0.04245626 -0.15905945\n",
      "  0.05217466 -0.19546877  0.73231025 -0.00642149 -0.00789139  0.02956456\n",
      " -0.00969776  0.036332   -0.13611533 -0.01191762  0.04464853 -0.16727265\n",
      "  0.62667544]\n"
     ]
    }
   ],
   "source": [
    "# data merge\n",
    "train_X = montly_sales_except0.loc[:, montly_sales.columns != \"item_cnt_month\"]\n",
    "train_y = montly_sales_except0[\"item_cnt_month\"]\n",
    "\n",
    "train_X = pd.merge(train_X, shop_item_cnt, on = [\"date_block_num\", \"shop_id\", \"item_id\"], how = \"left\") \n",
    "train_X[\"shop_item_cnt\"] = train_X[\"shop_item_cnt\"].fillna(0)\n",
    "\n",
    "train_X = pd.merge(train_X, item_cnt, on = [\"date_block_num\", \"item_id\"], how = \"left\")\n",
    "train_X[\"item_cnt\"] = train_X[\"item_cnt\"].fillna(0)\n",
    "\n",
    "train_X = pd.merge(train_X, shop_cnt, on = [\"date_block_num\", \"shop_id\"], how = \"left\")\n",
    "train_X[\"shop_cnt\"] = train_X[\"shop_cnt\"].fillna(0)\n",
    "\n",
    "# 설명변수 제외하고 drop\n",
    "train_X = train_X.drop([\"date_block_num\", \"shop_id\", \"item_id\"], axis = 1)\n",
    "train_y.index = list(range(0, 1545900))\n",
    "\n",
    "# numpy 자료형으로 변환하고 standardization\n",
    "train_X_np = train_X.to_numpy()\n",
    "train_y_np = train_y.to_numpy()\n",
    "\n",
    "std_scaler = preprocessing.StandardScaler().fit(train_X)\n",
    "train_X_np = std_scaler.transform(train_X)\n",
    "\n",
    "print(\"train_X numpy [:5] : \")\n",
    "print(train_X_np[:5])\n",
    "print(train_X_np.shape)\n",
    "\n",
    "print(\"\\ntrain_y numpy [:5] : \")\n",
    "print(train_y_np[:5])\n",
    "print(train_y_np.shape, \"\\n\\n\")\n",
    "\n",
    "# polynomial data 로 변환\n",
    "poly = PolynomialFeatures(degree = 3, include_bias = False)\n",
    "train_X_np_poly = make_poly_data(train_X_np, poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dc30f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polynomial regression MSE: -41.251003 (11.033622)\n",
      "polynomial regression r2: 0.463917 (0.111436)\n"
     ]
    }
   ],
   "source": [
    "poly3_model = LinearRegression()\n",
    "MSE, r2 = poly_regression_train(train_X_np_poly, train_y_np, poly3_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c55990",
   "metadata": {},
   "source": [
    "3 가지의 설정으로 regression 을 돌려보았다. polynomial 의 차수가 올라갈수록 score 가 좋아지기는 했지만,  \n",
    "가장 결과가 잘 나온 3차항 회귀에서도 MSE 는 41, r2 는 0.46 정도가 나왔는데 **r2 스코어가 0.7 이상은 나와야 쓸만한 모델인 것을  \n",
    "감안하면** 결과가 잘 나오지는 않은것을 알 수 있었다.  \n",
    "<br>\n",
    "차수를 더 늘리면 오차가 좀더 줄어들 수도 있다고 생각했지만, 그렇다면 차라리 딥러닝 라이브러리로 gpu 를 사용해서 계산하는 나을 것 같아서 우선 train data 의 label 값 분포를 살펴보고 다른 모델을 시도해보기로 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5321993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean :  2.274873536451258\n",
      "min :  -22.0\n",
      "max :  2253.0\n",
      "square root of MSE :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-f37ac2048bf5>:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  print(\"square root of MSE : \", MSE**(1/2))\n"
     ]
    }
   ],
   "source": [
    "hist = plt.hist(train_y_np, range=(0, 30), bins = 50)\n",
    "plt.title(\"lables\")\n",
    "plt.show()\n",
    "\n",
    "print(\"mean : \", train_y_np.mean())\n",
    "print(\"min : \", train_y_np.min())\n",
    "print(\"max : \", train_y_np.max())\n",
    "\n",
    "print(\"square root of MSE : \", MSE**(1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a30d6b",
   "metadata": {},
   "source": [
    "label 값의 분포를 살펴보면 대부분이 1 ~ 5 사이에 분포하는 것에 비해 최댓값(2253) 이 굉장히 큰 것을 알 수 있었다.  \n",
    "상점들마다 특별히 잘 팔리는 상품이 있고, 대부분의 상품들은 5개 이하로 팔리는 것으로 보인다.  \n",
    "<br>\n",
    "따라서 회귀를 사용할 경우 그래프가 1 ~ 5 의 라벨값을 가지는 아이템 기준으로 맞춰지고 cnt 가 큰 아이템에서 오차가 크게 발생하여 MSE score 가 좋게 나오지 못한 것이라는 가정을 하였다.  \n",
    "<br>\n",
    "실제로 error 가 가장 큰 item 20 개를 뽑았을 때 전부 label 값(montly_cnt) 가 큰 아이템들이었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d7625a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 items with big errors -> \n",
      "train_y : pred_y_mse_sort\n",
      "2253.0   151.62994547501222\n",
      "1644.0   9.614543795500492\n",
      "1644.0   9.746952676541715\n",
      "1242.0   1.5003293141183627\n",
      "1127.0   23.592326275251548\n",
      "1074.0   1.5306972720445418\n",
      "1117.0   108.68584021392113\n",
      "903.0    1.6067730217977232\n",
      "904.0    4.720201912266497\n",
      "813.0    1.5619521451735652\n",
      "1000.0   297.50116129347555\n",
      "766.0    81.40713725664912\n",
      "680.0    18.61384428912676\n",
      "716.0    85.5192102126681\n",
      "751.0    122.06586863667661\n",
      "597.0    14.140284275457805\n",
      "597.0    14.30099761233046\n",
      "742.0    179.84830299259824\n",
      "563.0    1.492184042684534\n",
      "550.0    1.4864043425981817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "poly3_model.fit(train_X_np_poly, train_y_np)\n",
    "pred_y = poly3_model.predict(train_X_np_poly)\n",
    "\n",
    "train_y_np_reshape = train_y_np.copy().reshape(1, -1) \n",
    "pred_y_reshape = pred_y.reshape(1, -1)\n",
    "\n",
    "MSE_multioutput = mean_squared_error(train_y_np_reshape, pred_y_reshape, multioutput = \"raw_values\")\n",
    "MSE_sort_top20 = np.argsort(MSE_multioutput)[::-1][:20]\n",
    "\n",
    "train_y_mse_sort = train_y_np[MSE_sort_top20]\n",
    "pred_y_mse_sort = pred_y[MSE_sort_top20]\n",
    "\n",
    "print(\"Top 20 items with big errors -> \")\n",
    "print(\"train_y : pred_y_mse_sort\")\n",
    "for i in range(20):\n",
    "    print(\"{0:<9}{1}\".format(train_y_mse_sort[i], pred_y_mse_sort[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
